{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FPGROWTH_DMT_TRUMP_HILARY.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPbMM9KFOjgO"
      },
      "source": [
        "#Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_l-SJMpO--L"
      },
      "source": [
        "import time\n",
        "start_t = y\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import fpg as fp\n",
        "import timeit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ycEvng7wZdu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cf41bfee-2d51-4314-99c7-6fa3ffbdfdaf"
      },
      "source": [
        "pip install memory_profiler"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: memory_profiler in /usr/local/lib/python3.6/dist-packages (0.58.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from memory_profiler) (5.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Muj5RkFxiwW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "698cb423-66e9-436b-e109-9bc2665ce329"
      },
      "source": [
        "%load_ext memory_profiler"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The memory_profiler extension is already loaded. To reload it, use:\n",
            "  %reload_ext memory_profiler\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql19kiQPPQbV"
      },
      "source": [
        "#Reading Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIiQjEP3Pm4q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "059fe5aa-da9e-4432-d0d8-3de50c67b867"
      },
      "source": [
        "#handle, text, lang = en, retweet_count, favourite_count\n",
        "data = pd.read_csv(\"tweets.csv\")\n",
        "keep_columns = [\"handle\", \"text\", \"lang\"]\n",
        "\n",
        "# removing columns of data which we won't be dealing with and keeping only keep_columns\n",
        "remove_columns_list = list(set(data.columns)-set(keep_columns))\n",
        "data.drop(columns = remove_columns_list, inplace = True)\n",
        "\n",
        "# keeping rows which have tweets in english\n",
        "data = data[data.lang == \"en\"]\n",
        "data.drop(columns = [\"lang\"], inplace=True)\n",
        "data.to_csv(\"twitter.csv\")\n",
        "\n",
        "hillary = data[data.handle == \"HillaryClinton\"]\n",
        "hillary.drop(columns = [\"handle\"], inplace=True)\n",
        "hillary.to_csv(\"Hillary.csv\")\n",
        "\n",
        "trump = data[data.handle == \"realDonaldTrump\"]\n",
        "trump.drop(columns = [\"handle\"], inplace=True)\n",
        "trump.to_csv(\"Trump.csv\")\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4169: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_cMrl8fQ517"
      },
      "source": [
        "#Data Cleaning and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0arVEj5eQ78C"
      },
      "source": [
        "# data cleaning\n",
        "clean_data = ['',\"will\",\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"arent\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\",\"below\", \"between\", \"both\", \"but\", \"by\",\"can\", \"cant\", \"cannot\", \"could\", \"couldnt\", \"did\",\"didn't\", \"do\", \"does\", \"doesnt\", \"doing\",\"dont\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"hadnt\",\"has\", \"hasnt\", \"have\", \"havent\", \"having\",\"he\", \"hed\", \"hell\", \"hes\", \"her\",\"here\", \"heres\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\",\"id\", \"ill\", \"im\", \"ive\", \"if\",\"in\", \"into\", \"is\", \"isnt\", \"it\",\"its\", \"its\", \"itself\", \"lets\", \"me\",\"more\", \"most\", \"mustnt\", \"my\", \"myself\", \"no\", \"nor\", \"not\", \"of\", \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"shant\", \"she\", \"shed\", \"shell\", \"shes\", \"should\", \"shouldnt\", \"so\", \"some\", \"such\", \"than\", \"that\", \"thats\", \"the\", \"their\", \"theirs\", \"them\",\"themselves\", \"then\", \"there\", \"theres\", \"these\", \"they\", \"theyd\", \"theyll\", \"theyre\", \"theyve\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\",\"wasnt\", \"we\", \"wed\", \"well\", \"were\", \"weve\", \"were\", \"werent\", \"what\", \"whats\", \"when\", \"when's\", \"where\", \"wheres\", \"which\",\"while\", \"who\", \"whos\", \"whom\", \"why\",\"whys\", \"with\", \"wont\", \"would\", \"wouldnt\",\"you\", \"youd\", \"youll\", \"youre\", \"youve\", \"your\", \"yours\",\"yourself\", \"yourselves\"]\n",
        "punctuation = list(string.punctuation + \"”’â€™\")\n",
        "\n",
        "def clean(x):\n",
        "    # make lowercase\n",
        "    x = x.lower()\n",
        "\n",
        "    #x = x.replace(\"â€™\",\"\") if x.find(\"â€™\") else x\n",
        "    #x = x.replace(\"â†\",\"\") if x.find(\"â€™\") else x\n",
        "\n",
        "    # to remove punctuation\n",
        "    temp = ''\n",
        "    for i in x:\n",
        "        if i in punctuation or i.isnumeric():\n",
        "            continue\n",
        "        temp += i\n",
        "    x = temp\n",
        "\n",
        "    # remove links\n",
        "\n",
        "    if x.find(\"http\") != -1 :\n",
        "        pos = x.find(\"http\")\n",
        "        space_pos = x.find(\" \", pos)\n",
        "        x = x[:pos] #x[0:pos] + x[space_pos:] if space_pos != -1 else x[0:pos]\n",
        "\n",
        "    # removing common words\n",
        "\n",
        "    words = x.split(\" \")\n",
        "    temp = \"\"\n",
        "    for i in words:\n",
        "        if i not in clean_data:\n",
        "            temp += i+\" \"\n",
        "\n",
        "    x = temp.strip()\n",
        "    return x\n",
        "\n",
        "def preprocessing(Data):\n",
        "    transactions = []\n",
        "    for i,j in Data.iterrows():\n",
        "        str = j.text\n",
        "        str = clean(str)\n",
        "        Data.at[i,'text'] = str.split(\" \")\n",
        "        transactions.append(str.split(\" \"))\n",
        "    Data.drop(Data.columns[[0]], axis = 1, inplace = True)\n",
        "    Data.to_csv(\"trial.csv\")\n",
        "    return transactions\n",
        "\n",
        "data_hillary = pd.read_csv(\"Hillary.csv\")\n",
        "# data = data.head(50) # to reduce number of rows while testing\n",
        "transactions_h = preprocessing(data_hillary)\n",
        "\n",
        "data_trump = pd.read_csv(\"Trump.csv\")\n",
        "# data = data.head(50) # to reduce number of rows while testing\n",
        "transactions_t = preprocessing(data_trump)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4Hf8rcKSzws"
      },
      "source": [
        "#Training Dataset based on FP algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4HNzQEsS2qI"
      },
      "source": [
        "def support_count(x,Data):\n",
        "    count = 0\n",
        "    x = set(x)\n",
        "    for j in Data['text']:\n",
        "        j = set(j)\n",
        "        if (x.issubset(j)):\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "def fpgrowth(transactions, minsup,Data):\n",
        "\n",
        "    # generating frequent patterns\n",
        "   \n",
        "    patterns = fp.find_frequent_patterns(transactions, minsup)\n",
        "\n",
        "    # generating association rules as {(left): ((right), confidence)}\n",
        "\n",
        "    rules = fp.generate_association_rules(patterns, 0.7)\n",
        "    \n",
        "    \n",
        "    rules_data = {}\n",
        "    rules_data[\"Antecedent\"] = list(rules.keys())\n",
        "    rules_data[\"Consequent\"] = [rules[i][0] for i in rules_data[\"Antecedent\"]]\n",
        "    rules_data[\"Confidence\"] = [rules[i][1] for i in rules_data[\"Antecedent\"]]\n",
        "\n",
        "    # calculating support of RHS aka consequent\n",
        "\n",
        "    support_RHS = []\n",
        "    for i in rules_data[\"Consequent\"]:\n",
        "        a = support_count(i,Data)\n",
        "        support_RHS.append(a*1.0/len(Data))\n",
        "    # calculating support of consequent and antecedent\n",
        "    support_total = []\n",
        "    for i in range(len(rules_data[\"Confidence\"])):\n",
        "        a = support_count(rules_data[\"Antecedent\"][i],Data)\n",
        "        support_total.append(rules_data[\"Confidence\"][i]*a/len(Data))    \n",
        "    \n",
        "    rules_data['RHS_support'] = support_RHS\n",
        "    rules_data['Total_support'] = support_total\n",
        "\n",
        "    # calculating support of LHS aka antecedent\n",
        "    support_LHS = []\n",
        "    for i in range(len(rules_data[\"Confidence\"])):\n",
        "        support_LHS.append(rules_data['Total_support'][i] / rules_data[\"Confidence\"][i] )\n",
        "    rules_data['LHS_support'] = support_LHS     \n",
        "\n",
        "    # calculating lift\n",
        "\n",
        "    lift = []\n",
        "    for i in range(len(rules_data[\"Confidence\"])):\n",
        "        lift.append( rules_data[\"Confidence\"][i] / rules_data['RHS_support'][i])\n",
        "    rules_data['Lift'] = lift\n",
        "\n",
        "    # storing results in .csv file\n",
        "\n",
        "    results = pd.DataFrame.from_dict(rules_data)\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Hixql0a671g"
      },
      "source": [
        "#Executing Hillary Tweet analysis and sorting based on Lift"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtjKYxbYTAkY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4fe61d2-6ed1-4414-ecf1-03776801d762"
      },
      "source": [
        "\n",
        "results_Hillary = fpgrowth(transactions_h, 10, data_hillary) # 10 is the minimum support\n",
        "\n",
        "results_Hillary.to_csv(\"Results - Hillary.csv\") #adding sorted data\n",
        "\n",
        "print(\"Results of FP Growth Algorithm for Hillary is saved in file Results - Hillary.csv\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results of FP Growth Algorithm for Hillary is saved in file Results - Hillary.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbb50mh7oJqc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "outputId": "89c2cc1d-55c1-404b-b1ef-a774a3ded111"
      },
      "source": [
        "results_Hillary.nlargest(n = 20, columns = 'Lift')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Antecedent</th>\n",
              "      <th>Consequent</th>\n",
              "      <th>Confidence</th>\n",
              "      <th>RHS_support</th>\n",
              "      <th>Total_support</th>\n",
              "      <th>LHS_support</th>\n",
              "      <th>Lift</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>(minimum,)</td>\n",
              "      <td>(wage,)</td>\n",
              "      <td>1.125000</td>\n",
              "      <td>0.005775</td>\n",
              "      <td>0.005414</td>\n",
              "      <td>0.004812</td>\n",
              "      <td>194.812500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(human,)</td>\n",
              "      <td>(rights,)</td>\n",
              "      <td>2.583333</td>\n",
              "      <td>0.013474</td>\n",
              "      <td>0.006630</td>\n",
              "      <td>0.002567</td>\n",
              "      <td>191.720238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>(pay, share)</td>\n",
              "      <td>(fair,)</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.004812</td>\n",
              "      <td>0.003208</td>\n",
              "      <td>0.003529</td>\n",
              "      <td>188.909091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>(wage,)</td>\n",
              "      <td>(minimum,)</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.004812</td>\n",
              "      <td>0.004950</td>\n",
              "      <td>0.005775</td>\n",
              "      <td>178.114286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>(fair, pay)</td>\n",
              "      <td>(share,)</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.007700</td>\n",
              "      <td>0.003208</td>\n",
              "      <td>0.003208</td>\n",
              "      <td>129.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>(college, debt)</td>\n",
              "      <td>(student,)</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.007700</td>\n",
              "      <td>0.003208</td>\n",
              "      <td>0.003529</td>\n",
              "      <td>118.068182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>(star,)</td>\n",
              "      <td>(gold,)</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.007379</td>\n",
              "      <td>0.004171</td>\n",
              "      <td>0.004812</td>\n",
              "      <td>117.452174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>(mike,)</td>\n",
              "      <td>(pence,)</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.007379</td>\n",
              "      <td>0.005454</td>\n",
              "      <td>0.006416</td>\n",
              "      <td>115.193478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(oval,)</td>\n",
              "      <td>(office,)</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.007379</td>\n",
              "      <td>0.003208</td>\n",
              "      <td>0.003850</td>\n",
              "      <td>112.934783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>(pence,)</td>\n",
              "      <td>(mike,)</td>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.006416</td>\n",
              "      <td>0.005227</td>\n",
              "      <td>0.007379</td>\n",
              "      <td>110.393750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>(street,)</td>\n",
              "      <td>(wall,)</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.009304</td>\n",
              "      <td>0.004171</td>\n",
              "      <td>0.004171</td>\n",
              "      <td>107.482759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>(hillary, states)</td>\n",
              "      <td>(clinton, president)</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.008983</td>\n",
              "      <td>0.003208</td>\n",
              "      <td>0.003529</td>\n",
              "      <td>101.201299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(mate,)</td>\n",
              "      <td>(running,)</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.010587</td>\n",
              "      <td>0.003529</td>\n",
              "      <td>0.003529</td>\n",
              "      <td>94.454545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>(pay, women)</td>\n",
              "      <td>(equal,)</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.008983</td>\n",
              "      <td>0.002941</td>\n",
              "      <td>0.003529</td>\n",
              "      <td>92.767857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(barack,)</td>\n",
              "      <td>(obama,)</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.008662</td>\n",
              "      <td>0.003208</td>\n",
              "      <td>0.004171</td>\n",
              "      <td>88.803419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>(leave,)</td>\n",
              "      <td>(paid,)</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.008341</td>\n",
              "      <td>0.004171</td>\n",
              "      <td>0.005775</td>\n",
              "      <td>86.583333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>(college, student)</td>\n",
              "      <td>(debt,)</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.011229</td>\n",
              "      <td>0.003208</td>\n",
              "      <td>0.003529</td>\n",
              "      <td>80.961039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>(womens,)</td>\n",
              "      <td>(rights,)</td>\n",
              "      <td>1.037037</td>\n",
              "      <td>0.013474</td>\n",
              "      <td>0.008318</td>\n",
              "      <td>0.008021</td>\n",
              "      <td>76.962963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>(clinton, states)</td>\n",
              "      <td>(hillary, president)</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.013474</td>\n",
              "      <td>0.003208</td>\n",
              "      <td>0.003529</td>\n",
              "      <td>67.467532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(lobby,)</td>\n",
              "      <td>(gun,)</td>\n",
              "      <td>1.090909</td>\n",
              "      <td>0.016362</td>\n",
              "      <td>0.003850</td>\n",
              "      <td>0.003529</td>\n",
              "      <td>66.673797</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Antecedent            Consequent  Confidence  RHS_support  \\\n",
              "15          (minimum,)               (wage,)    1.125000     0.005775   \n",
              "4             (human,)             (rights,)    2.583333     0.013474   \n",
              "14        (pay, share)               (fair,)    0.909091     0.004812   \n",
              "16             (wage,)            (minimum,)    0.857143     0.004812   \n",
              "12         (fair, pay)              (share,)    1.000000     0.007700   \n",
              "33     (college, debt)            (student,)    0.909091     0.007700   \n",
              "11             (star,)               (gold,)    0.866667     0.007379   \n",
              "29             (mike,)              (pence,)    0.850000     0.007379   \n",
              "5              (oval,)             (office,)    0.833333     0.007379   \n",
              "30            (pence,)               (mike,)    0.708333     0.006416   \n",
              "10           (street,)               (wall,)    1.000000     0.009304   \n",
              "57   (hillary, states)  (clinton, president)    0.909091     0.008983   \n",
              "3              (mate,)            (running,)    1.000000     0.010587   \n",
              "39        (pay, women)              (equal,)    0.833333     0.008983   \n",
              "7            (barack,)              (obama,)    0.769231     0.008662   \n",
              "21            (leave,)               (paid,)    0.722222     0.008341   \n",
              "34  (college, student)               (debt,)    0.909091     0.011229   \n",
              "37           (womens,)             (rights,)    1.037037     0.013474   \n",
              "56   (clinton, states)  (hillary, president)    0.909091     0.013474   \n",
              "2             (lobby,)                (gun,)    1.090909     0.016362   \n",
              "\n",
              "    Total_support  LHS_support        Lift  \n",
              "15       0.005414     0.004812  194.812500  \n",
              "4        0.006630     0.002567  191.720238  \n",
              "14       0.003208     0.003529  188.909091  \n",
              "16       0.004950     0.005775  178.114286  \n",
              "12       0.003208     0.003208  129.875000  \n",
              "33       0.003208     0.003529  118.068182  \n",
              "11       0.004171     0.004812  117.452174  \n",
              "29       0.005454     0.006416  115.193478  \n",
              "5        0.003208     0.003850  112.934783  \n",
              "30       0.005227     0.007379  110.393750  \n",
              "10       0.004171     0.004171  107.482759  \n",
              "57       0.003208     0.003529  101.201299  \n",
              "3        0.003529     0.003529   94.454545  \n",
              "39       0.002941     0.003529   92.767857  \n",
              "7        0.003208     0.004171   88.803419  \n",
              "21       0.004171     0.005775   86.583333  \n",
              "34       0.003208     0.003529   80.961039  \n",
              "37       0.008318     0.008021   76.962963  \n",
              "56       0.003208     0.003529   67.467532  \n",
              "2        0.003850     0.003529   66.673797  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0666dRC7NpZ"
      },
      "source": [
        "#Executing Trump Tweet analyses and sorting based on Lift"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW5ykifhTKbC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "aef526f8-e412-4afb-f8a0-eb11257af271"
      },
      "source": [
        "\n",
        "%memit results_Trump = fpgrowth(transactions_t, 10, data_trump) # 10 is the minimum suppor\n",
        "\n",
        "results_Trump.to_csv(\"Results - Trump.csv\")\n",
        "print(\"Results of FP Growth Algorithm for Trump is saved in file Results - Trump.csv\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "peak memory: 229.90 MiB, increment: 0.01 MiB\n",
            "Results of FP Growth Algorithm for Trump is saved in file Results - Trump.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_8fdarYqFld",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "outputId": "a45748fe-2743-4d95-99d6-f7148fca599c"
      },
      "source": [
        "results_Trump.nlargest(n = 20, columns = 'Lift')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Antecedent</th>\n",
              "      <th>Consequent</th>\n",
              "      <th>Confidence</th>\n",
              "      <th>RHS_support</th>\n",
              "      <th>Total_support</th>\n",
              "      <th>LHS_support</th>\n",
              "      <th>Lift</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>(elizabeth, native)</td>\n",
              "      <td>(american, goofy)</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>0.003513</td>\n",
              "      <td>0.003513</td>\n",
              "      <td>0.003194</td>\n",
              "      <td>313.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>(core,)</td>\n",
              "      <td>(common,)</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>0.003833</td>\n",
              "      <td>0.003162</td>\n",
              "      <td>0.002874</td>\n",
              "      <td>287.008333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>(common,)</td>\n",
              "      <td>(core,)</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.002874</td>\n",
              "      <td>0.003011</td>\n",
              "      <td>0.003833</td>\n",
              "      <td>273.341270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(graham,)</td>\n",
              "      <td>(lindsey,)</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.002874</td>\n",
              "      <td>0.002948</td>\n",
              "      <td>0.003833</td>\n",
              "      <td>267.606838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(lindsey,)</td>\n",
              "      <td>(graham,)</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.003833</td>\n",
              "      <td>0.002874</td>\n",
              "      <td>0.002874</td>\n",
              "      <td>260.916667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(prayers,)</td>\n",
              "      <td>(thoughts,)</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.003194</td>\n",
              "      <td>0.003194</td>\n",
              "      <td>0.004152</td>\n",
              "      <td>240.846154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(thoughts,)</td>\n",
              "      <td>(prayers,)</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.004152</td>\n",
              "      <td>0.003194</td>\n",
              "      <td>0.003194</td>\n",
              "      <td>240.846154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>(born, ted)</td>\n",
              "      <td>(canada,)</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>0.004791</td>\n",
              "      <td>0.002811</td>\n",
              "      <td>0.002555</td>\n",
              "      <td>229.606667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>(hillary, wall)</td>\n",
              "      <td>(street,)</td>\n",
              "      <td>1.166667</td>\n",
              "      <td>0.005110</td>\n",
              "      <td>0.004099</td>\n",
              "      <td>0.003513</td>\n",
              "      <td>228.302083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>(law, officers)</td>\n",
              "      <td>(enforcement,)</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.004791</td>\n",
              "      <td>0.003513</td>\n",
              "      <td>0.003513</td>\n",
              "      <td>208.733333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>(enforcement, law)</td>\n",
              "      <td>(officers,)</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.005110</td>\n",
              "      <td>0.004192</td>\n",
              "      <td>0.004791</td>\n",
              "      <td>171.226562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>(foreign,)</td>\n",
              "      <td>(policy,)</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.004791</td>\n",
              "      <td>0.003194</td>\n",
              "      <td>0.004471</td>\n",
              "      <td>149.095238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>(enforcement, officers)</td>\n",
              "      <td>(law,)</td>\n",
              "      <td>1.166667</td>\n",
              "      <td>0.007985</td>\n",
              "      <td>0.004099</td>\n",
              "      <td>0.003513</td>\n",
              "      <td>146.113333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>(american, warren)</td>\n",
              "      <td>(elizabeth, goofy)</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.007346</td>\n",
              "      <td>0.002874</td>\n",
              "      <td>0.002874</td>\n",
              "      <td>136.130435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>(american, goofy, native)</td>\n",
              "      <td>(elizabeth,)</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.007665</td>\n",
              "      <td>0.003194</td>\n",
              "      <td>0.003194</td>\n",
              "      <td>130.458333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>(goofy, warren)</td>\n",
              "      <td>(elizabeth,)</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.007665</td>\n",
              "      <td>0.007027</td>\n",
              "      <td>0.007027</td>\n",
              "      <td>130.458333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>(american, goofy, warren)</td>\n",
              "      <td>(elizabeth,)</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.007665</td>\n",
              "      <td>0.002874</td>\n",
              "      <td>0.002874</td>\n",
              "      <td>130.458333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>(warren,)</td>\n",
              "      <td>(elizabeth, goofy)</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>0.007346</td>\n",
              "      <td>0.007027</td>\n",
              "      <td>0.007346</td>\n",
              "      <td>130.211720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>(elizabeth, goofy)</td>\n",
              "      <td>(warren,)</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>0.007346</td>\n",
              "      <td>0.007027</td>\n",
              "      <td>0.007346</td>\n",
              "      <td>130.211720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>(american, elizabeth)</td>\n",
              "      <td>(goofy,)</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.007985</td>\n",
              "      <td>0.003194</td>\n",
              "      <td>0.003194</td>\n",
              "      <td>125.240000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Antecedent          Consequent  Confidence  RHS_support  \\\n",
              "13        (elizabeth, native)   (american, goofy)    1.100000     0.003513   \n",
              "9                     (core,)           (common,)    1.100000     0.003833   \n",
              "8                   (common,)             (core,)    0.785714     0.002874   \n",
              "2                   (graham,)          (lindsey,)    0.769231     0.002874   \n",
              "3                  (lindsey,)           (graham,)    1.000000     0.003833   \n",
              "0                  (prayers,)         (thoughts,)    0.769231     0.003194   \n",
              "1                 (thoughts,)          (prayers,)    1.000000     0.004152   \n",
              "30                (born, ted)           (canada,)    1.100000     0.004791   \n",
              "35            (hillary, wall)           (street,)    1.166667     0.005110   \n",
              "27            (law, officers)      (enforcement,)    1.000000     0.004791   \n",
              "25         (enforcement, law)         (officers,)    0.875000     0.005110   \n",
              "22                 (foreign,)           (policy,)    0.714286     0.004791   \n",
              "26    (enforcement, officers)              (law,)    1.166667     0.007985   \n",
              "53         (american, warren)  (elizabeth, goofy)    1.000000     0.007346   \n",
              "17  (american, goofy, native)        (elizabeth,)    1.000000     0.007665   \n",
              "52            (goofy, warren)        (elizabeth,)    1.000000     0.007665   \n",
              "55  (american, goofy, warren)        (elizabeth,)    1.000000     0.007665   \n",
              "48                  (warren,)  (elizabeth, goofy)    0.956522     0.007346   \n",
              "50         (elizabeth, goofy)           (warren,)    0.956522     0.007346   \n",
              "11      (american, elizabeth)            (goofy,)    1.000000     0.007985   \n",
              "\n",
              "    Total_support  LHS_support        Lift  \n",
              "13       0.003513     0.003194  313.100000  \n",
              "9        0.003162     0.002874  287.008333  \n",
              "8        0.003011     0.003833  273.341270  \n",
              "2        0.002948     0.003833  267.606838  \n",
              "3        0.002874     0.002874  260.916667  \n",
              "0        0.003194     0.004152  240.846154  \n",
              "1        0.003194     0.003194  240.846154  \n",
              "30       0.002811     0.002555  229.606667  \n",
              "35       0.004099     0.003513  228.302083  \n",
              "27       0.003513     0.003513  208.733333  \n",
              "25       0.004192     0.004791  171.226562  \n",
              "22       0.003194     0.004471  149.095238  \n",
              "26       0.004099     0.003513  146.113333  \n",
              "53       0.002874     0.002874  136.130435  \n",
              "17       0.003194     0.003194  130.458333  \n",
              "52       0.007027     0.007027  130.458333  \n",
              "55       0.002874     0.002874  130.458333  \n",
              "48       0.007027     0.007346  130.211720  \n",
              "50       0.007027     0.007346  130.211720  \n",
              "11       0.003194     0.003194  125.240000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm5pl8bOCm8x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "c7467043-8405-4e02-e61b-868e5b077499"
      },
      "source": [
        "end_t = time.time()\n",
        "print(start_t)\n",
        "print(end_t)\n",
        "print(end_t - start_t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1603342582.9658668\n",
            "1603342589.5387442\n",
            "6.572877407073975\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}